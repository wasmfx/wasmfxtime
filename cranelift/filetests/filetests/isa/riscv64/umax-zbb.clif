test compile precise-output
set unwind_info=false
target riscv64 has_zbb

function %umax_i8(i8, i8) -> i8{
block0(v0: i8, v1: i8):
    v2 = umax v0, v1
    return v2
}

; VCode:
; block0:
;   andi a3,a0,255
;   andi a5,a1,255
;   maxu a0,a3,a5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   andi a3, a0, 0xff
;   andi a5, a1, 0xff
;   .byte 0x33, 0xf5, 0xf6, 0x0a
;   ret

function %umax_i16(i16, i16) -> i16{
block0(v0: i16, v1: i16):
    v2 = umax v0, v1
    return v2
}

; VCode:
; block0:
;   zext.h a3,a0
;   zext.h a5,a1
;   maxu a0,a3,a5
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0xbb, 0x46, 0x05, 0x08
;   .byte 0xbb, 0xc7, 0x05, 0x08
;   .byte 0x33, 0xf5, 0xf6, 0x0a
;   ret

function %umax_i32(i32, i32) -> i32{
block0(v0: i32, v1: i32):
    v2 = umax v0, v1
    return v2
}

; VCode:
; block0:
;   slli a3,a0,32
;   srli a5,a3,32
;   slli a1,a1,32
;   srli a3,a1,32
;   maxu a0,a5,a3
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   slli a3, a0, 0x20
;   srli a5, a3, 0x20
;   slli a1, a1, 0x20
;   srli a3, a1, 0x20
;   .byte 0x33, 0xf5, 0xd7, 0x0a
;   ret

function %umax_i64(i64, i64) -> i64{
block0(v0: i64, v1: i64):
    v2 = umax v0, v1
    return v2
}

; VCode:
; block0:
;   maxu a0,a0,a1
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   .byte 0x33, 0x75, 0xb5, 0x0a
;   ret

function %umax_i128(i128, i128) -> i128{
block0(v0: i128, v1: i128):
    v2 = umax v0, v1
    return v2
}

; VCode:
;   add sp,-16
;   sd ra,8(sp)
;   sd fp,0(sp)
;   mv fp,sp
;   sd s3,-8(sp)
;   add sp,-16
; block0:
;   ugt a5,[a0,a1],[a2,a3]##ty=i128
;   mv a4,a0
;   mv s3,a1
;   select [a0,a1],[a4,s3],[a2,a3]##condition=(a5 ne zero)
;   add sp,+16
;   ld s3,-8(sp)
;   ld ra,8(sp)
;   ld fp,0(sp)
;   add sp,+16
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   addi sp, sp, -0x10
;   sd ra, 8(sp)
;   sd s0, 0(sp)
;   mv s0, sp
;   sd s3, -8(sp)
;   addi sp, sp, -0x10
; block1: ; offset 0x18
;   bltu a3, a1, 0xc
;   bne a1, a3, 0x10
;   bgeu a2, a0, 0xc
;   addi a5, zero, 1
;   j 8
;   mv a5, zero
;   mv a4, a0
;   mv s3, a1
;   beqz a5, 0x10
;   mv a0, a4
;   mv a1, s3
;   j 0xc
;   mv a0, a2
;   mv a1, a3
;   addi sp, sp, 0x10
;   ld s3, -8(sp)
;   ld ra, 8(sp)
;   ld s0, 0(sp)
;   addi sp, sp, 0x10
;   ret

