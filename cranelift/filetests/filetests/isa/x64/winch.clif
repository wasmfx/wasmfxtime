test compile precise-output
target x86_64

function %f1() winch {
block0:
    return
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f2(i64, i64, i64, i64, i64, i64) -> i64 winch {
  sig0 = () winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  call fn0()
  return v0
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $16, %rsp
; block0:
;   movq    %rdi, rsp(0 + virtual offset)
;   load_ext_name %g+0, %r10
;   call    *%r10
;   movq    rsp(0 + virtual offset), %rax
;   addq    %rsp, $16, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x10, %rsp
; block1: ; offset 0x8
;   movq %rdi, (%rsp)
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   callq *%r10
;   movq (%rsp), %rax
;   addq $0x10, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f3(i64, i64, i64, i64, i64, i64) -> i64 {
  sig0 = () winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  call fn0()
  return v0
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $64, %rsp
;   movq    %rbx, 16(%rsp)
;   movq    %r12, 24(%rsp)
;   movq    %r13, 32(%rsp)
;   movq    %r14, 40(%rsp)
;   movq    %r15, 48(%rsp)
; block0:
;   movq    %rdi, rsp(0 + virtual offset)
;   load_ext_name %g+0, %r10
;   call    *%r10
;   movq    rsp(0 + virtual offset), %rax
;   movq    16(%rsp), %rbx
;   movq    24(%rsp), %r12
;   movq    32(%rsp), %r13
;   movq    40(%rsp), %r14
;   movq    48(%rsp), %r15
;   addq    %rsp, $64, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x40, %rsp
;   movq %rbx, 0x10(%rsp)
;   movq %r12, 0x18(%rsp)
;   movq %r13, 0x20(%rsp)
;   movq %r14, 0x28(%rsp)
;   movq %r15, 0x30(%rsp)
; block1: ; offset 0x21
;   movq %rdi, (%rsp)
;   movabsq $0, %r10 ; reloc_external Abs8 %g 0
;   callq *%r10
;   movq (%rsp), %rax
;   movq 0x10(%rsp), %rbx
;   movq 0x18(%rsp), %r12
;   movq 0x20(%rsp), %r13
;   movq 0x28(%rsp), %r14
;   movq 0x30(%rsp), %r15
;   addq $0x40, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f4(i64, i64, i64, i64, i64, i64) -> i64 winch {
  sig0 = (i64, i64, i64, i64, i64, i64) -> i64 winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  v6 = call fn0(v5, v1, v2, v3, v4, v0)
  return v6
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
; block0:
;   movq    %rdi, %rax
;   movq    %r9, %rdi
;   movq    %rax, %r9
;   load_ext_name %g+0, %r11
;   call    *%r11
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
; block1: ; offset 0x4
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   movabsq $0, %r11 ; reloc_external Abs8 %g 0
;   callq *%r11
;   movq %rbp, %rsp
;   popq %rbp
;   retq

function %f5(i64, i64, i64, i64, i64, i64) -> i64 {
  sig0 = (i64, i64, i64, i64, i64, i64) -> i64 winch
  fn0 = %g sig0

block0(v0:i64, v1:i64, v2:i64, v3:i64, v4:i64, v5:i64):
  v6 = call fn0(v5, v1, v2, v3, v4, v0)
  return v6
}

; VCode:
;   pushq   %rbp
;   movq    %rsp, %rbp
;   subq    %rsp, $48, %rsp
;   movq    %rbx, 0(%rsp)
;   movq    %r12, 8(%rsp)
;   movq    %r13, 16(%rsp)
;   movq    %r14, 24(%rsp)
;   movq    %r15, 32(%rsp)
; block0:
;   movq    %rdi, %rax
;   movq    %r9, %rdi
;   movq    %rax, %r9
;   load_ext_name %g+0, %r11
;   call    *%r11
;   movq    0(%rsp), %rbx
;   movq    8(%rsp), %r12
;   movq    16(%rsp), %r13
;   movq    24(%rsp), %r14
;   movq    32(%rsp), %r15
;   addq    %rsp, $48, %rsp
;   movq    %rbp, %rsp
;   popq    %rbp
;   ret
;
; Disassembled:
; block0: ; offset 0x0
;   pushq %rbp
;   movq %rsp, %rbp
;   subq $0x30, %rsp
;   movq %rbx, (%rsp)
;   movq %r12, 8(%rsp)
;   movq %r13, 0x10(%rsp)
;   movq %r14, 0x18(%rsp)
;   movq %r15, 0x20(%rsp)
; block1: ; offset 0x20
;   movq %rdi, %rax
;   movq %r9, %rdi
;   movq %rax, %r9
;   movabsq $0, %r11 ; reloc_external Abs8 %g 0
;   callq *%r11
;   movq (%rsp), %rbx
;   movq 8(%rsp), %r12
;   movq 0x10(%rsp), %r13
;   movq 0x18(%rsp), %r14
;   movq 0x20(%rsp), %r15
;   addq $0x30, %rsp
;   movq %rbp, %rsp
;   popq %rbp
;   retq

